{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shcho-chapter4-wgan-cifar-20200223-v09.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNYIMISYEOuUt99wkgjBhyk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9200ea5277a64d0c87ee94fa4452d020": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_798265ec5e8b4eec89aa3d82ce18823f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_13e765533ef54fb29b38206977ba6d7f",
              "IPY_MODEL_bee834a23a8e41b4839e32d3fe5a3831"
            ]
          }
        },
        "798265ec5e8b4eec89aa3d82ce18823f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "13e765533ef54fb29b38206977ba6d7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "IntProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f8e816eecff448f9b28f2a2f4bd9e752",
            "_dom_classes": [],
            "description": "",
            "_model_name": "IntProgressModel",
            "bar_style": "success",
            "max": 47,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 47,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b4e770f5e16848f6a4197abc2ef44fdc"
          }
        },
        "bee834a23a8e41b4839e32d3fe5a3831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_76b3531d7007450e969aca023de4bad9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100% 47/47 [00:00&lt;00:00, 721.39it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_adabf7766adb4408a6d3cecc8df25d27"
          }
        },
        "f8e816eecff448f9b28f2a2f4bd9e752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b4e770f5e16848f6a4197abc2ef44fdc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "76b3531d7007450e969aca023de4bad9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "adabf7766adb4408a6d3cecc8df25d27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JungOhLee/GDL_pytorch/blob/shcho/shcho_chapter4_wgan_cifar_20200223_v09.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Mz5yuU5aSmJ",
        "colab_type": "code",
        "outputId": "c923af02-4c74-4861-d5f8-0cb8a13cd756",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVrkRlIEaa_n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.optim as optim\n",
        "import  tarfile\n",
        "from torchsummary import summary as ptsum\n",
        "import torch.autograd as autograd\n",
        "import png\n",
        "\n",
        "from PIL import Image"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPiGihCWbsIC",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4ZWoSB2bpRd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oM4EDvU4aaDj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import collections\n",
        "from torch.autograd import Variable\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hf1kVGW6abBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm import tqdm_notebook as tqdm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qTYkwRsZjaC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(data):\n",
        "    if isinstance(data, bytes):  return data.decode('ascii')\n",
        "    if isinstance(data, dict):   return dict(map(convert, data.items()))\n",
        "    if isinstance(data, tuple):  return map(convert, data)\n",
        "    return data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-A8xzyynY2U9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrlHmBf5ZbLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_HOME_DIR = './drive/My Drive/Colab Notebooks/mlstudy/gan/gdl_code/data/cifar-10-batches-py/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeB1T3jCavqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_files = [item for item in os.listdir(DATA_HOME_DIR) if item not in ['readme.html', 'batches.meta']]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xA7L8kkZoov",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_dict_list = []\n",
        "for item in data_files:\n",
        "  DATA_DIR = DATA_HOME_DIR + item\n",
        "  data_dict  = convert(unpickle(DATA_DIR))\n",
        "\n",
        "  data_dict_list.append(data_dict)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhxoR29S_-jc",
        "colab_type": "code",
        "outputId": "f0b62732-11ef-4b82-bb10-4de346a239d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(data_dict_list)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ka1X_Hqyaa9p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_x_train = []\n",
        "for item in data_dict_list:\n",
        "  for _label, _data in zip(item['labels'], item['data']):\n",
        "    if _label == 7:\n",
        "      _x_train.append(_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBmV_r0zAIun",
        "colab_type": "code",
        "outputId": "b82032b7-9b5c-44c9-9b31-7e5107e89be2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(_x_train)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vY7SjB2Yd3oR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_x_train_stacked = np.stack(_x_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOZ9DLLLd7qi",
        "colab_type": "code",
        "outputId": "9dff4d7d-cf34-4c8a-cc06-6251963b9e78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "_x_train_stacked.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 3072)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa3wGISwcyzo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = _x_train_stacked.reshape(-1,3,32,32)/255\n",
        "for_figure_x_train = x_train.transpose([0,2,3,1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kevb_ct5aa7v",
        "colab_type": "code",
        "outputId": "9d832aaf-c2a7-4043-d1ab-4a5ae9e388e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "for_figure_x_train.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbpkQZH5aa5Z",
        "colab_type": "code",
        "outputId": "1e76e906-9036-4c54-8244-cb6c8a6cdfa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        }
      },
      "source": [
        "plt.imshow(for_figure_x_train[3,:,:,:])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f8694dbcba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQiSCnF2IRJCzC5EIcnYhEkHOLkQi/F+BVYdik4haMgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kh68_i5Uaa3P",
        "colab_type": "text"
      },
      "source": [
        "## Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_MzSex5aa2G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Discriminator_PT(nn.Module): # GAN Pytorch\n",
        "    def __init__(self\n",
        "        , input_dim\n",
        "        , discriminator_conv_filters\n",
        "        , discriminator_conv_kernel_size\n",
        "        , discriminator_conv_strides\n",
        "        , discriminator_batch_norm_momentum\n",
        "        , discriminator_activation\n",
        "        , discriminator_dropout_rate\n",
        "        , discriminator_learning_rate\n",
        "        , optimiser\n",
        "        , z_dim\n",
        "        , activation_function\n",
        "        ):\n",
        "        \n",
        "        super(Discriminator_PT, self).__init__()\n",
        "\n",
        "        self.name = 'gan'\n",
        "\n",
        "        self.input_dim = input_dim\n",
        "        \n",
        "        ## discriminator\n",
        "        self.discriminator_conv_filters_input = [input_dim[0]] + discriminator_conv_filters[:-1]\n",
        "        self.discriminator_conv_filters_output = discriminator_conv_filters\n",
        "        self.discriminator_conv_kernel_size = discriminator_conv_kernel_size\n",
        "        self.discriminator_conv_strides = discriminator_conv_strides\n",
        "        self.discriminator_batch_norm_momentum = discriminator_batch_norm_momentum\n",
        "        self.discriminator_activation = discriminator_activation\n",
        "        self.discriminator_dropout_rate = discriminator_dropout_rate\n",
        "        self.discriminator_learning_rate = discriminator_learning_rate\n",
        "        self.activation_function = activation_function\n",
        "\n",
        "        \n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.n_layers_discriminator = len(discriminator_conv_filters)\n",
        "\n",
        "        # initializer\n",
        "        self.weight_init = torch.normal(mean=torch.Tensor([0.]), std=0.02)\n",
        "\n",
        "        self.d_losses = []\n",
        "        self.g_losses = []\n",
        "\n",
        "        self.epoch = 0\n",
        "        \n",
        "        self.discriminator_conv_layers = nn.Sequential()\n",
        "        self.discriminator_output_shape = collections.OrderedDict()\n",
        "        \n",
        "        self.discriminator_output_shape['Input'] = self.input_dim\n",
        "\n",
        "        self._build_discriminator()\n",
        "\n",
        "    def _build_discriminator(self):\n",
        "\n",
        "        print('Build Discriminator')\n",
        "        current_layer_name = 'Input'\n",
        "        current_input_shape = self.discriminator_output_shape[current_layer_name]\n",
        "        \n",
        "        for i in range(self.n_layers_discriminator):\n",
        "            \n",
        "            current_filter, input_H, input_W = current_input_shape\n",
        "            current_layer_name = 'Layer {} Conv2d'.format(i)\n",
        "            \n",
        "            kernel_H, kernel_W = self.discriminator_conv_kernel_size[i]\n",
        "            stride_H, stride_W  = self.discriminator_conv_strides[i]\n",
        "            \n",
        "            _output_H = int((input_H-kernel_H)/stride_H) + 1 # int 논리 맞는지 확인\n",
        "            _output_W = int((input_W-kernel_W)/stride_W) + 1\n",
        "            \n",
        "            target_output_H = np.ceil(input_H/stride_H)\n",
        "            target_output_W = np.ceil(input_W/stride_W)\n",
        "            \n",
        "            if target_output_H != _output_H:\n",
        "                padding_H = int(np.ceil(((target_output_H-1)*stride_H-input_H+kernel_H)/2))\n",
        "            else:\n",
        "                padding_H = 0\n",
        "                \n",
        "            if target_output_W != _output_W:\n",
        "                padding_W = int(np.ceil(((target_output_W-1)*stride_W-input_W+kernel_W)/2))\n",
        "            else:\n",
        "                padding_W = 0\n",
        "            \n",
        "            output_H = int((input_H-kernel_H+2*padding_H)/stride_H) + 1\n",
        "            output_W = int((input_W-kernel_W+2*padding_W)/stride_W) + 1\n",
        "            \n",
        "            print(output_H, output_W)\n",
        "            \n",
        "            self.discriminator_output_shape[current_layer_name] = [self.discriminator_conv_filters_output[i], output_H, output_W]\n",
        "            current_input_shape = self.discriminator_output_shape[current_layer_name]\n",
        "            \n",
        "            conv = nn.Conv2d(\n",
        "                        self.discriminator_conv_filters_input[i]\n",
        "                        , self.discriminator_conv_filters_output[i]\n",
        "                        , kernel_size = self.discriminator_conv_kernel_size[i]\n",
        "                        , stride = self.discriminator_conv_strides[i]\n",
        "                        , padding = (padding_H, padding_W)\n",
        "#                         , kernel_initializer = self.weight_init\n",
        "                        )\n",
        "            # conv.weight.data.apply_(self.weight_init)\n",
        "\n",
        "            self.discriminator_conv_layers.add_module(\n",
        "                current_layer_name,\n",
        "                conv\n",
        "            )\n",
        "\n",
        "            if self.discriminator_batch_norm_momentum and i > 0:\n",
        "                self.discriminator_conv_layers.add_module('Layer {} BatchNorm2d'.format(i), \n",
        "                                            nn.BatchNorm2d(self.discriminator_conv_filters_output[i],\n",
        "                                                          momentum=self.discriminator_batch_norm_momentum))\n",
        "\n",
        "            self.discriminator_conv_layers.add_module('Layer {} LeakyReLU'.format(i), nn.LeakyReLU())\n",
        "\n",
        "            if self.discriminator_dropout_rate:\n",
        "                self.discriminator_conv_layers.add_module('Layer {} Dropout2d'.format(i), nn.Dropout2d(p=self.discriminator_dropout_rate))\n",
        "            \n",
        "        self.discriminator_cnn_output_shape = current_input_shape\n",
        "        \n",
        "        self.discriminator_flattened_shape = np.prod(self.discriminator_cnn_output_shape)\n",
        "\n",
        "        \n",
        "        ## Flatten 층 생성\n",
        "        ## 역시 이 전에 reshaping은 forward에서\n",
        "        self.discriminator_flattened = nn.Linear(self.discriminator_flattened_shape, 1)\n",
        "        self.Sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        x = self.discriminator_conv_layers(x)\n",
        "        x = x.reshape(x.size()[0],-1)\n",
        "        \n",
        "#         print(x.shape)\n",
        "        \n",
        "        x = self.discriminator_flattened(x)\n",
        "\n",
        "        if self.activation_function == 'Sigmoid':\n",
        "          x = self.Sigmoid(x)\n",
        "        \n",
        "        \n",
        "        return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cbiH1Kx3aayt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## generator 는 똑같다.\n",
        "\n",
        "class Generator_PT(nn.Module): # GAN Pytorch\n",
        "    def __init__(self\n",
        "        , generator_initial_dense_layer_size\n",
        "        , input_dim\n",
        "        , generator_upsample\n",
        "        , generator_conv_filters\n",
        "        , generator_conv_kernel_size\n",
        "        , generator_conv_strides\n",
        "        , generator_batch_norm_momentum\n",
        "        , generator_activation\n",
        "        , generator_dropout_rate\n",
        "        , generator_learning_rate\n",
        "        , optimiser\n",
        "        , z_dim\n",
        "        , discriminator_output_shape\n",
        "        , discriminator_cnn_output_shape\n",
        "        ):\n",
        "        \n",
        "        super(Generator_PT, self).__init__()\n",
        "\n",
        "        # Necessary information from discriminator\n",
        "        self.discriminator_output_shape = discriminator_output_shape\n",
        "        self.discriminator_cnn_output_shape = discriminator_cnn_output_shape\n",
        "        \n",
        "        self.name = 'gan'\n",
        "        self.input_dim = input_dim\n",
        "        \n",
        "        ## generator\n",
        "        self.generator_initial_dense_layer_size = generator_initial_dense_layer_size\n",
        "        self.generator_upsample = generator_upsample\n",
        "        self.generator_conv_filters_input = [self.generator_initial_dense_layer_size[0]] + generator_conv_filters[:-1]\n",
        "        self.generator_conv_filters_output = generator_conv_filters\n",
        "        self.generator_conv_kernel_size = generator_conv_kernel_size\n",
        "        self.generator_conv_strides = generator_conv_strides\n",
        "        self.generator_batch_norm_momentum = generator_batch_norm_momentum\n",
        "        self.generator_activation = generator_activation\n",
        "        self.generator_dropout_rate = generator_dropout_rate\n",
        "        self.generator_learning_rate = generator_learning_rate\n",
        "        \n",
        "        self.z_dim = z_dim\n",
        "\n",
        "        self.n_layers_generator = len(generator_conv_filters)\n",
        "\n",
        "        # initializer\n",
        "        self.weight_init = torch.normal(mean=torch.Tensor([0.]), std=0.02)\n",
        "\n",
        "        self.d_losses = []\n",
        "        self.g_losses = []\n",
        "\n",
        "        self.epoch = 0\n",
        "                \n",
        "        self.generator_conv_layers = nn.Sequential()\n",
        "        self.generator_output_shape = collections.OrderedDict()\n",
        "        \n",
        "        self.generator_initial_layers = nn.Sequential()\n",
        "        \n",
        "        self.generator_output_shape['Input'] = self.input_dim\n",
        "        self.generator_output_shape['Input'] = self.generator_initial_dense_layer_size\n",
        "\n",
        "\n",
        "        self._build_generator()\n",
        "\n",
        "    def get_activation(self, activation):\n",
        "        if activation == 'leaky_relu':\n",
        "            layer = LeakyReLU(alpha = 0.2)\n",
        "        else:\n",
        "            layer = Activation(activation)\n",
        "        return layer\n",
        "\n",
        "    def _build_generator(self):\n",
        "\n",
        "        print('Build Generator')\n",
        "        ### THE generator\n",
        "\n",
        "        self.generator_initial_layers.add_module('Layer Generator Input', \n",
        "                                            nn.Linear(self.z_dim, np.prod(self.generator_initial_dense_layer_size)))\n",
        "\n",
        "        self.generator_initial_layers.add_module('Layer Generator Input LeakyReLU', nn.LeakyReLU())\n",
        "        \n",
        "        if self.generator_dropout_rate:\n",
        "            self.generator_initial_layers.add_module('Layer Generator Input Dropout2d', nn.Dropout2d(p=self.generator_dropout_rate))\n",
        "            \n",
        "        # 이건 forward가서\n",
        "#         x = Reshape(self.generator_initial_dense_layer_size)(x)\n",
        "        \n",
        "        current_layer_name = 'Input'\n",
        "        current_input_shape = self.generator_output_shape[current_layer_name]\n",
        "        \n",
        "        discriminator_conv_layer_name_list = []\n",
        "        \n",
        "#         print(self.discriminator_output_shape)\n",
        "        \n",
        "        for item in self.discriminator_output_shape:\n",
        "            discriminator_conv_layer_name_list.append(item)\n",
        "        discriminator_conv_layer_name_list.reverse()\n",
        "\n",
        "#         print(discriminator_conv_layer_name_list)\n",
        "        for i, discriminator_layer_name in zip(range(self.n_layers_generator), discriminator_conv_layer_name_list[1:]):\n",
        "            \n",
        "#             print(discriminator_layer_name)\n",
        "            \n",
        "            discriminator_layer_shape = self.discriminator_output_shape[discriminator_layer_name]\n",
        "            \n",
        "            current_filter, input_H, input_W = discriminator_layer_shape\n",
        "            current_layer_name = 'Layer {} Conv2d'.format(i)\n",
        "\n",
        "        \n",
        "            if self.generator_upsample[i] == 2:\n",
        "                \n",
        "                current_filter, input_H, input_W = current_input_shape\n",
        "                \n",
        "                input_H = input_H*self.generator_upsample[i]\n",
        "                input_W = input_W*self.generator_upsample[i]\n",
        "                \n",
        "                current_layer_name = 'Layer {} Conv2d'.format(i)\n",
        "\n",
        "                kernel_H, kernel_W = self.generator_conv_kernel_size[i]\n",
        "                stride_H, stride_W  = self.generator_conv_strides[i]\n",
        "\n",
        "                _output_H = int((input_H-kernel_H)/stride_H) + 1\n",
        "                _output_W = int((input_W-kernel_W)/stride_W) + 1\n",
        "\n",
        "                target_output_H = int(input_H/stride_H)\n",
        "                target_output_W = int(input_W/stride_W)\n",
        "\n",
        "                if target_output_H != _output_H:\n",
        "                    padding_H = int(np.ceil(((target_output_H-1)*stride_H-input_H+kernel_H)/2))\n",
        "                else:\n",
        "                    padding_H = 0\n",
        "\n",
        "                if target_output_W != _output_W:\n",
        "                    padding_W = int(np.ceil(((target_output_W-1)*stride_W-input_W+kernel_W)/2))\n",
        "                else:\n",
        "                    padding_W = 0\n",
        "\n",
        "                output_H = int((input_H-kernel_H+2*padding_H)/stride_H) + 1\n",
        "                output_W = int((input_W-kernel_W+2*padding_W)/stride_W) + 1\n",
        "                \n",
        "                self.generator_output_shape[current_layer_name] = [self.generator_conv_filters_output[i], output_H, output_W]\n",
        "                current_input_shape = self.generator_output_shape[current_layer_name]\n",
        "                \n",
        "\n",
        "                self.generator_conv_layers.add_module('Layer {} Upsample'.format(i),\n",
        "                                            nn.Upsample(scale_factor=self.generator_upsample[i])\n",
        "                                           )\n",
        "                \n",
        "\n",
        "                self.generator_conv_layers.add_module(\n",
        "                    current_layer_name,\n",
        "                    nn.Conv2d(\n",
        "                            self.generator_conv_filters_input[i]\n",
        "                            , self.generator_conv_filters_output[i]\n",
        "                            , kernel_size = self.generator_conv_kernel_size[i]\n",
        "                            , stride = self.generator_conv_strides[i]\n",
        "                            , padding = (padding_H, padding_W)\n",
        "    #                         , kernel_initializer = self.weight_init\n",
        "                            )\n",
        "                )\n",
        "                \n",
        "            else:\n",
        "                \n",
        "                # defining size\n",
        "                current_filter, input_H, input_W = current_input_shape\n",
        "                current_layer_name = 'Layer {} Conv2d'.format(i)\n",
        "\n",
        "                kernel_H, kernel_W = self.generator_conv_kernel_size[i]\n",
        "                stride_H, stride_W = self.generator_conv_strides[i]\n",
        "\n",
        "                target_output_H = max(input_H*stride_H,discriminator_layer_shape[1])\n",
        "                target_output_W = max(input_W*stride_W,discriminator_layer_shape[2])\n",
        "\n",
        "                padding_output_padding_H = (input_H - 1) * stride_H + (kernel_H - 1) + 1 - target_output_H\n",
        "                padding_output_padding_W = (input_W - 1) * stride_W + (kernel_W - 1) + 1 - target_output_W\n",
        "                \n",
        "                if padding_output_padding_H%2==0:\n",
        "                    output_padding_H = 0\n",
        "                    padding_H = int(padding_output_padding_H/2)\n",
        "                else:\n",
        "                    output_padding_H = max(stride_H-1,0)\n",
        "                    padding_H = int((padding_output_padding_H+output_padding_H)/2)\n",
        "                    \n",
        "                if padding_output_padding_W%2==0:\n",
        "                    output_padding_W = 0\n",
        "                    padding_W = int(padding_output_padding_W/2)\n",
        "                else:\n",
        "                    output_padding_W = max(stride_W-1,0)\n",
        "                    padding_W = int((padding_output_padding_W+output_padding_W)/2)\n",
        "\n",
        "                # padding_H = max(0, padding_H)\n",
        "                # padding_W = max(0, padding_W)\n",
        "                    \n",
        "                output_H = (input_H-1)*stride_H + (kernel_H-1)+1 - 2 * padding_H + output_padding_H\n",
        "                output_W = (input_W-1)*stride_W + (kernel_W-1)+1 - 2 * padding_W + output_padding_W\n",
        "\n",
        "                self.generator_output_shape[current_layer_name] = [self.generator_conv_filters_output[i], output_H, output_W]\n",
        "                current_input_shape = self.generator_output_shape[current_layer_name]\n",
        "                \n",
        "                # print('\\n')\n",
        "                # print(output_H, target_output_H, padding_H, output_padding_H, stride_H, kernel_H)\n",
        "\n",
        "                # self.output_shape[current_layer_name] = [self.generator_conv_filters_output[i], output_H, output_W]\n",
        "                # current_input_shape = self.output_shape[current_layer_name]\n",
        "\n",
        "                self.generator_conv_layers.add_module(current_layer_name,\n",
        "                                nn.ConvTranspose2d(self.generator_conv_filters_input[i]\n",
        "                                        , self.generator_conv_filters_output[i]\n",
        "                                        , kernel_size = self.generator_conv_kernel_size[i]\n",
        "                                        , stride = self.generator_conv_strides[i]\n",
        "                                        , padding = (padding_H, padding_W)\n",
        "                                        , output_padding = (output_padding_H, output_padding_W)\n",
        "                                        ))\n",
        "\n",
        "            print(output_H, output_W, padding_H, padding_W)\n",
        "                \n",
        "            if i < self.n_layers_generator - 1:\n",
        "\n",
        "                if self.generator_batch_norm_momentum:\n",
        "                    self.generator_conv_layers.add_module('Layer {} BatchNorm2d'.format(i), \n",
        "                                                nn.BatchNorm2d(self.generator_conv_filters_output[i],\n",
        "                                                              momentum=self.generator_batch_norm_momentum))\n",
        "\n",
        "                self.generator_conv_layers.add_module('Layer {} LeakyReLU'.format(i), nn.LeakyReLU())\n",
        "                    \n",
        "                \n",
        "            # else:\n",
        "\n",
        "            self.tanh = nn.Tanh()\n",
        "\n",
        "\n",
        "        # 이 부분도 forward로\n",
        "#         generator_output = x\n",
        "\n",
        "#         self.generator = Model(generator_input, generator_output)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        \n",
        "        x = self.generator_initial_layers(x)\n",
        "        # print(x.shape)\n",
        "        \n",
        "        x = x.reshape([x.size()[0]]+list(self.generator_initial_dense_layer_size))\n",
        "        \n",
        "        x = self.generator_conv_layers(x)\n",
        "        x = self.tanh(x)\n",
        "        \n",
        "        return x\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nH6DOaSGfxV9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "z_dim = 100"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmFgaVFdjvPD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_dim = (3, 32, 32)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7sst1KTwslGS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation_function = 'WGANGP'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEKYgsy-Aprk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation_function = 'Sigmoid'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "668V6wCO-l2V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "activation_function = 'WGAN'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHizhS16xJaP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if activation_function == 'Sigmoid':\n",
        "  discriminator_learning_rate = 0.0008\n",
        "  generator_learning_rate = 0.0004\n",
        "else:\n",
        "  discriminator_learning_rate = 0.00005\n",
        "  generator_learning_rate = 0.00005"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTFGVZL7tNRN",
        "colab_type": "text"
      },
      "source": [
        "device = 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cnyHdhg6aauk",
        "colab_type": "code",
        "outputId": "a208a9e3-b9d9-4ca9-dc6b-6166216de497",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "Discriminator = Discriminator_PT(\n",
        "    input_dim = input_dim\n",
        "    , discriminator_conv_filters = [32,64,128,128]\n",
        "    , discriminator_conv_kernel_size = [(5,5),(5,5),(5,5),(5,5)]\n",
        "    , discriminator_conv_strides = [(2,2),(2,2),(2,2),(1,1)]\n",
        "    , discriminator_batch_norm_momentum = 0.5\n",
        "    , discriminator_activation = 'relu'\n",
        "    , discriminator_dropout_rate = 0.4\n",
        "    , discriminator_learning_rate = discriminator_learning_rate\n",
        "    , optimiser = 'rmsprop'\n",
        "    , z_dim = z_dim\n",
        "    , activation_function = activation_function\n",
        "    ).to(device)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build Discriminator\n",
            "16 16\n",
            "8 8\n",
            "4 4\n",
            "4 4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U8z_nYgVlEAp",
        "colab_type": "code",
        "outputId": "8020f948-bd56-47ad-c50b-07aa577adb68",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "Generator = Generator_PT(\n",
        "    input_dim = input_dim\n",
        "    , generator_initial_dense_layer_size = (128, 4, 4)\n",
        "    , generator_upsample = [2,2, 2, 1]\n",
        "    , generator_conv_filters = [128,64, 64,3]\n",
        "    , generator_conv_kernel_size = [(5,5),(5,5),(5,5),(5,5)]\n",
        "    , generator_conv_strides = [(1,1),(1,1), (1,1), (1,1)]\n",
        "    , generator_batch_norm_momentum = 0.8\n",
        "    , generator_dropout_rate = 0.25\n",
        "    , generator_activation = 'relu'\n",
        "    , generator_learning_rate = generator_learning_rate\n",
        "    , optimiser = 'rmsprop'\n",
        "    , z_dim = z_dim\n",
        "    , discriminator_output_shape = Discriminator.discriminator_output_shape\n",
        "    , discriminator_cnn_output_shape = Discriminator.discriminator_cnn_output_shape\n",
        "    ).to(device)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Build Generator\n",
            "8 8 2 2\n",
            "16 16 2 2\n",
            "32 32 2 2\n",
            "32 32 2 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gHav9Fi7aaqI",
        "colab_type": "text"
      },
      "source": [
        "## 학습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nPfH9Z7ollkZ",
        "colab_type": "code",
        "outputId": "2bc52b36-4f9a-42d7-a438-89620048a061",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "Discriminator.train()\n",
        "Generator.train()\n",
        "print('Train mode')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train mode\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RB91ndpaakV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Binary Cross Entropy loss\n",
        "criterion = nn.BCELoss().to(device)\n",
        "\n",
        "# 생성자의 매개 변수를 최적화하는 Adam optimizer\n",
        "G_optimizer = optim.RMSprop(Generator.parameters(), lr=Generator.generator_learning_rate)\n",
        "# 구분자의 매개 변수를 최적화하는 Adam optimizer\n",
        "D_optimizer = optim.RMSprop(Discriminator.parameters(), \n",
        "                            lr=Discriminator.discriminator_learning_rate)\n",
        "\n",
        "# optim.RMSprop\n",
        "# optim.Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRKWgdX8aaiR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_pt = torch.from_numpy(x_train).float().to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ShnanfPCaagf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k-qCBwrtaae0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN8tJ4Iob9Uz",
        "colab_type": "code",
        "outputId": "9bc712c8-39ac-4784-eb0a-b032810ad71f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "9200ea5277a64d0c87ee94fa4452d020",
            "798265ec5e8b4eec89aa3d82ce18823f",
            "13e765533ef54fb29b38206977ba6d7f",
            "bee834a23a8e41b4839e32d3fe5a3831",
            "f8e816eecff448f9b28f2a2f4bd9e752",
            "b4e770f5e16848f6a4197abc2ef44fdc",
            "76b3531d7007450e969aca023de4bad9",
            "adabf7766adb4408a6d3cecc8df25d27"
          ]
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "    for real_data in tqdm(DataLoader(x_train_pt, batch_size = batch_size, shuffle=True)):\n",
        "      pass"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9200ea5277a64d0c87ee94fa4452d020",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(IntProgress(value=0, max=47), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4Y5GbhgdQ69",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "EPOCHS = 5000"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2hkQJfgqi9x",
        "colab_type": "text"
      },
      "source": [
        "## activation_function\n",
        "\n",
        "이것이 'None'이면 WGAN이다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6A2kcB72sflL",
        "colab_type": "code",
        "outputId": "56a9c15f-767e-4c9a-c0b0-c427f11b6148",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(activation_function)"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WGAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zuubn8M7-8kr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.autograd import Variable"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlfC8MkHyiDo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "CLIP_THRESHOLD = 0.01"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BywL244r9xEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_gradient_penalty(D, real_samples, fake_samples):\n",
        "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
        "    # Random weight term for interpolation between real and fake samples\n",
        "    alpha = torch.from_numpy(np.random.random((real_samples.size(0), 1, 1, 1))).to(device)\n",
        "    # Get random interpolation between real and fake samples\n",
        "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
        "    d_interpolates = D(interpolates.float())\n",
        "    fake = torch.ones(real_samples.shape[0], 1)\n",
        "    # Get gradient w.r.t. interpolates\n",
        "    gradients = autograd.grad(\n",
        "        outputs=d_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=fake,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )[0]\n",
        "    gradients = gradients.view(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
        "    return gradient_penalty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jjnBXDa2iPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if activation_function == 'Sigmoid':\n",
        "  discriminator_train_number = 1\n",
        "else:\n",
        "  discriminator_train_number = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvmlzsHzwZu",
        "colab_type": "text"
      },
      "source": [
        "https://github.com/eriklindernoren/PyTorch-GAN/blob/master/implementations/wgan_gp/wgan_gp.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PlYEQ5sVSrt",
        "colab_type": "text"
      },
      "source": [
        "## Clipping 시키는 예시\n",
        "\n",
        "https://github.com/Zeleni9/pytorch-wgan/blob/master/models/wgan_clipping.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcDDH6I-BECW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Loss weight for gradient penalty\n",
        "lambda_gp = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ReZP9GpHKZk",
        "colab_type": "code",
        "outputId": "b0a8fa9d-5628-4f4c-e7f8-c628fce0a902",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(activation_function)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WGAN\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6X0JMB5MqnC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "try:\n",
        "  restart_epoch = epoch\n",
        "except:\n",
        "  restart_epoch = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_tf6blIaacZ",
        "colab_type": "code",
        "outputId": "fa1fba3c-7f44-4ef8-e150-189ff790337b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "try:\n",
        "  restart_epoch = epoch\n",
        "except:\n",
        "  restart_epoch = 0\n",
        "\n",
        "for epoch in range(restart_epoch, EPOCHS):\n",
        "  \n",
        "  total_D_loss = 0\n",
        "  total_G_loss = 0\n",
        "  \n",
        "  batch_count_for_generator = 0\n",
        "  # for real_data in tqdm(DataLoader(x_train_pt, batch_size = batch_size, shuffle=True)):\n",
        "  for real_data in DataLoader(x_train_pt, batch_size = batch_size, shuffle=True):\n",
        "    # print(batch_count_for_generator)\n",
        "    real_data_shape = real_data.shape[0]\n",
        "\n",
        "    if real_data_shape!=batch_size:\n",
        "      continue\n",
        "\n",
        "    target_real = Variable(torch.ones(real_data_shape, 1)).float().to(device)\n",
        "\n",
        "    ## 판별자\n",
        "    for p in Discriminator.parameters():\n",
        "      p.requires_grad = True  # to avoid computation\n",
        "    for p in Generator.parameters():\n",
        "      p.requires_grad = False  # to avoid computation\n",
        "    D_optimizer.zero_grad()\n",
        "    Discriminator.zero_grad()\n",
        "\n",
        "    if activation_function == 'WGAN':\n",
        "      for p in Discriminator.parameters():\n",
        "        p.data.clamp_(-CLIP_THRESHOLD, CLIP_THRESHOLD)\n",
        "\n",
        "    D_result_from_real = Discriminator(real_data)\n",
        "    z = (torch.randn((real_data_shape, z_dim))).to(device)\n",
        "    fake_data = Generator(z)\n",
        "    D_result_from_fake = Discriminator(fake_data)\n",
        "    \n",
        "    if activation_function == 'Sigmoid':\n",
        "      target_fake = Variable(torch.zeros(real_data_shape, 1)).float().to(device)\n",
        "\n",
        "      D_loss_real = criterion(D_result_from_real, target_real)\n",
        "      D_loss_fake = criterion(D_result_from_fake, target_fake)\n",
        "\n",
        "    else:\n",
        "      target_fake = Variable(torch.ones(real_data_shape, 1)).float().to(device)\n",
        "\n",
        "      # D_loss_real = (D_result_from_real * target_real).mean()\n",
        "      D_loss_real = torch.mean(D_result_from_real)\n",
        "      # from fake는 fake데이터를 discriminator가 평가한것. \n",
        "      # 이것에 target_fake를 곱하면, \n",
        "      # D_loss_fake = (D_result_from_fake * target_fake).mean()\n",
        "      D_loss_fake = torch.mean(D_result_from_fake)\n",
        "\n",
        "    if activation_function == 'WGANGP':\n",
        "      gradient_penalty = compute_gradient_penalty(Discriminator, real_data.data, fake_data.data)\n",
        "    else:\n",
        "      gradient_penalty = torch.from_numpy(np.array([0])).to(device)\n",
        "\n",
        "    if activation_function == 'Sigmoid':\n",
        "      D_loss = D_loss_real + D_loss_fake\n",
        "    elif activation_function == 'WGAN':\n",
        "      D_loss = -1 * (D_loss_real - D_loss_fake)\n",
        "    elif activation_function == 'WGANGP':\n",
        "      D_loss = -1 * (D_loss_real - D_loss_fake) + lambda_gp * gradient_penalty\n",
        "\n",
        "    # Discriminator.zero_grad()\n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "\n",
        "    # Clipping weights\n",
        "    # if activation_function == 'WGAN':\n",
        "    #   for temp_layer in Discriminator.discriminator_conv_layers:\n",
        "    #     if hasattr(temp_layer, 'weight'):\n",
        "    #       for temp_p in temp_layer02.parameters():\n",
        "    #         temp_p.data.clamp_(-CLIP_THRESHOLD, CLIP_THRESHOLD)\n",
        "    #   for temp_p in Discriminator.discriminator_flattened.parameters():\n",
        "    #     temp_p.data.clamp_(-CLIP_THRESHOLD, CLIP_THRESHOLD)\n",
        "    \n",
        "\n",
        "\n",
        "    if activation_function == 'Sigmoid':\n",
        "      batch_count_for_generator = 0\n",
        "\n",
        "    # Discriminator.train()\n",
        "    # Generator.train()\n",
        "\n",
        "    if batch_count_for_generator%5==0:\n",
        "      # print('generator',batch_count_for_generator)\n",
        "      for p in Discriminator.parameters():\n",
        "        p.requires_grad = False  # to avoid computation\n",
        "      for p in Generator.parameters():\n",
        "        p.requires_grad = True  # to avoid computation\n",
        "      G_optimizer.zero_grad()\n",
        "      Generator.zero_grad()\n",
        "      batch_count_for_generator = 0\n",
        "\n",
        "      ## 생성자\n",
        "\n",
        "      z = (torch.randn((real_data_shape, 100))).to(device)\n",
        "\n",
        "      fake_data = Generator(z)\n",
        "\n",
        "      D_result_from_fake = Discriminator(fake_data)\n",
        "\n",
        "      if activation_function == 'Sigmoid':\n",
        "        G_loss = criterion(D_result_from_fake, target_real)\n",
        "      else:\n",
        "        # G_loss = -1 * (D_result_from_fake * target_real).mean()\n",
        "        G_loss = -1 * torch.mean(D_result_from_fake)\n",
        "\n",
        "      G_loss.backward()\n",
        "      G_optimizer.step()\n",
        "\n",
        "      total_G_loss+=G_loss.item()\n",
        "\n",
        "    total_D_loss+=D_loss.item()\n",
        "    batch_count_for_generator+=1\n",
        "    \n",
        "    # print('\\t', D_loss.item())\n",
        "    # print('\\t', G_loss.item())\n",
        "\n",
        "  total_D_loss_numeric = round(total_D_loss,6)\n",
        "  total_G_loss_numeric = round(total_G_loss,6)\n",
        "\n",
        "  print_str = str(epoch) + ' ' + str(total_D_loss_numeric) + ' ' + str(total_G_loss_numeric)\n",
        "\n",
        "  print(print_str)\n",
        "\n",
        "  if epoch%10==0:\n",
        "    try:\n",
        "      torch.save(Discriminator.state_dict(), './drive/My Drive/Colab Notebooks/mlstudy/gan/gdl_code/trained_models/Discriminator.pt')\n",
        "      torch.save(Generator.state_dict(), './drive/My Drive/Colab Notebooks/mlstudy/gan/gdl_code/trained_models/Generator.pt')\n",
        "\n",
        "      Generator.eval()\n",
        "      for i in range(10):\n",
        "        generated_image = Generator(torch.randn([1,100]).to(device)).cpu().detach().numpy()[0].transpose(1,2,0)\n",
        "        generated_image02 = (((generated_image - generated_image.min())/((generated_image - generated_image.min()).max()))*255).astype(int)\n",
        "        img = Image.fromarray(np.uint8((generated_image02)))\n",
        "        img.save('./drive/My Drive/Colab Notebooks/mlstudy/gan/gdl_code/fig/image_{}.png'.format(i))\n",
        "      Generator.train()\n",
        "      \n",
        "    except:\n",
        "      pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "333 -9.2518 1.091965\n",
            "334 -8.957834 1.016505\n",
            "335 -9.331989 1.160553\n",
            "336 -8.642479 1.163365\n",
            "337 -10.007286 1.218336\n",
            "338 -8.874929 1.163759\n",
            "339 -8.524817 1.030848\n",
            "340 -9.177907 1.167954\n",
            "341 -9.021865 1.144822\n",
            "342 -9.563642 1.085433\n",
            "343 -9.530948 1.165575\n",
            "344 -8.998922 1.137707\n",
            "345 -9.134876 1.153312\n",
            "346 -9.49119 1.155174\n",
            "347 -8.748863 0.94522\n",
            "348 -9.882265 1.208\n",
            "349 -8.495804 1.173141\n",
            "350 -9.469656 1.165477\n",
            "351 -9.137828 1.229877\n",
            "352 -9.109135 1.219258\n",
            "353 -9.116688 1.137751\n",
            "354 -9.289638 1.161777\n",
            "355 -9.206695 1.113414\n",
            "356 -8.839629 1.262194\n",
            "357 -9.523347 1.118122\n",
            "358 -9.674909 1.242992\n",
            "359 -8.805984 1.064766\n",
            "360 -9.155401 1.150191\n",
            "361 -9.011026 1.223272\n",
            "362 -9.270594 1.187162\n",
            "363 -10.042325 1.176415\n",
            "364 -8.824216 1.176917\n",
            "365 -9.197322 1.258417\n",
            "366 -9.115946 1.165731\n",
            "367 -9.408002 1.164778\n",
            "368 -9.684373 1.236387\n",
            "369 -8.894471 1.157045\n",
            "370 -8.867021 1.107258\n",
            "371 -9.040951 1.253521\n",
            "372 -9.006661 1.24689\n",
            "373 -9.859563 0.998287\n",
            "374 -9.275534 1.315272\n",
            "375 -9.148767 1.158583\n",
            "376 -9.599768 1.179833\n",
            "377 -8.997547 1.176309\n",
            "378 -8.815691 1.212451\n",
            "379 -9.186366 1.166018\n",
            "380 -9.297651 1.219999\n",
            "381 -9.928699 1.167526\n",
            "382 -8.744896 1.238439\n",
            "383 -8.657789 1.145603\n",
            "384 -8.118856 1.199834\n",
            "385 -8.560816 1.144098\n",
            "386 -8.882618 1.230741\n",
            "387 -9.98656 1.225232\n",
            "388 -9.758732 1.24859\n",
            "389 -8.308393 1.06779\n",
            "390 -9.698639 1.176499\n",
            "391 -8.869156 1.131317\n",
            "392 -9.612896 1.152999\n",
            "393 -9.065964 1.104943\n",
            "394 -8.48732 1.170932\n",
            "395 -8.46116 0.998056\n",
            "396 -8.783746 1.053925\n",
            "397 -8.908643 1.199236\n",
            "398 -9.512332 1.148423\n",
            "399 -9.536009 1.228574\n",
            "400 -9.100243 0.997062\n",
            "401 -9.529559 1.191318\n",
            "402 -9.260251 1.218258\n",
            "403 -8.926366 1.150257\n",
            "404 -8.603661 1.133832\n",
            "405 -8.852401 1.037829\n",
            "406 -8.453856 1.131536\n",
            "407 -9.216186 1.004549\n",
            "408 -8.869268 1.163456\n",
            "409 -8.927909 1.240406\n",
            "410 -9.824159 1.022385\n",
            "411 -8.181228 1.070878\n",
            "412 -9.010899 1.002897\n",
            "413 -9.802517 1.208087\n",
            "414 -8.529012 1.115257\n",
            "415 -8.966968 1.208289\n",
            "416 -9.192746 1.201863\n",
            "417 -8.232192 1.17287\n",
            "418 -10.103244 1.054202\n",
            "419 -8.158682 1.005323\n",
            "420 -8.588467 1.075559\n",
            "421 -8.91494 1.005091\n",
            "422 -8.452386 1.219809\n",
            "423 -8.781468 1.004481\n",
            "424 -8.975379 1.152671\n",
            "425 -8.374219 1.057288\n",
            "426 -9.121385 1.126937\n",
            "427 -8.565081 1.127643\n",
            "428 -8.96925 1.062935\n",
            "429 -8.410124 1.138279\n",
            "430 -8.713019 1.033384\n",
            "431 -8.583588 1.214646\n",
            "432 -8.669004 1.156867\n",
            "433 -8.499324 1.066196\n",
            "434 -9.10995 1.162071\n",
            "435 -8.984486 1.270519\n",
            "436 -8.696674 1.147881\n",
            "437 -8.210513 1.034039\n",
            "438 -8.805058 1.159106\n",
            "439 -8.163857 1.180536\n",
            "440 -8.376705 1.237007\n",
            "441 -9.20516 1.047548\n",
            "442 -9.671398 1.166384\n",
            "443 -8.199948 1.139098\n",
            "444 -8.386718 1.103396\n",
            "445 -8.186315 1.187551\n",
            "446 -8.736913 1.145953\n",
            "447 -8.382063 1.177454\n",
            "448 -9.068977 1.031341\n",
            "449 -8.17304 1.289932\n",
            "450 -9.145787 1.153558\n",
            "451 -8.329465 0.981261\n",
            "452 -8.235401 1.158137\n",
            "453 -9.062682 0.988218\n",
            "454 -8.095081 1.053026\n",
            "455 -9.34404 1.146627\n",
            "456 -8.619209 1.174978\n",
            "457 -8.80614 1.22479\n",
            "458 -8.261257 1.121356\n",
            "459 -9.100565 1.155717\n",
            "460 -8.500809 1.181883\n",
            "461 -9.768644 1.080165\n",
            "462 -8.46845 1.131091\n",
            "463 -8.582449 1.143059\n",
            "464 -8.840886 1.130472\n",
            "465 -8.62286 1.037304\n",
            "466 -8.194874 1.204504\n",
            "467 -8.760608 1.138496\n",
            "468 -9.244093 1.107246\n",
            "469 -8.749519 1.107587\n",
            "470 -9.269974 1.169394\n",
            "471 -8.3977 1.175453\n",
            "472 -8.865915 1.090442\n",
            "473 -8.232665 1.221381\n",
            "474 -8.806589 1.067788\n",
            "475 -8.167936 1.025793\n",
            "476 -8.039168 1.248757\n",
            "477 -8.116894 1.090469\n",
            "478 -8.396261 1.189411\n",
            "479 -9.407458 1.097077\n",
            "480 -9.082073 1.030342\n",
            "481 -8.376979 1.180347\n",
            "482 -8.005646 1.043122\n",
            "483 -8.511966 1.114346\n",
            "484 -8.671093 1.03696\n",
            "485 -8.790187 1.041153\n",
            "486 -8.364607 0.9548\n",
            "487 -8.470758 1.065868\n",
            "488 -8.114444 1.189488\n",
            "489 -8.093879 1.02777\n",
            "490 -8.77581 1.249862\n",
            "491 -7.874463 1.07086\n",
            "492 -9.03321 1.059031\n",
            "493 -8.286751 1.01633\n",
            "494 -8.248321 1.199586\n",
            "495 -8.076583 1.084286\n",
            "496 -8.139111 1.257121\n",
            "497 -8.793373 1.072026\n",
            "498 -8.999971 1.036156\n",
            "499 -8.539702 1.138971\n",
            "500 -7.554734 1.12867\n",
            "501 -7.622791 0.96716\n",
            "502 -8.04945 1.049607\n",
            "503 -8.385485 1.033473\n",
            "504 -9.055345 1.104294\n",
            "505 -8.684044 1.002733\n",
            "506 -7.403871 0.937859\n",
            "507 -8.495754 1.083224\n",
            "508 -8.210445 0.975227\n",
            "509 -8.548583 1.153159\n",
            "510 -8.305418 1.159705\n",
            "511 -8.964921 1.05632\n",
            "512 -8.622021 1.186284\n",
            "513 -8.610667 0.922868\n",
            "514 -7.99637 1.046138\n",
            "515 -8.510513 1.049749\n",
            "516 -7.841112 0.954495\n",
            "517 -8.065744 0.967643\n",
            "518 -8.077636 1.057584\n",
            "519 -8.420925 1.195963\n",
            "520 -8.432297 1.105885\n",
            "521 -7.729523 1.089588\n",
            "522 -8.912957 1.181515\n",
            "523 -8.371236 1.140818\n",
            "524 -9.609302 1.090108\n",
            "525 -7.382615 1.170709\n",
            "526 -8.074669 1.088205\n",
            "527 -8.619427 1.143405\n",
            "528 -8.142931 1.122732\n",
            "529 -7.703664 1.07587\n",
            "530 -8.64046 1.180594\n",
            "531 -8.772604 0.986149\n",
            "532 -8.074862 0.987262\n",
            "533 -8.00117 1.105221\n",
            "534 -8.328301 1.049796\n",
            "535 -7.788571 1.125217\n",
            "536 -7.506918 0.980588\n",
            "537 -8.335517 1.037437\n",
            "538 -7.975304 1.095827\n",
            "539 -8.130321 1.126818\n",
            "540 -8.439425 1.150584\n",
            "541 -9.100022 1.064783\n",
            "542 -7.902916 1.168664\n",
            "543 -8.48436 1.198359\n",
            "544 -8.548827 1.066635\n",
            "545 -7.992512 1.064055\n",
            "546 -8.897536 1.029991\n",
            "547 -7.638651 1.166374\n",
            "548 -8.978535 1.085471\n",
            "549 -8.086586 1.076674\n",
            "550 -7.812125 1.118407\n",
            "551 -7.825402 1.162587\n",
            "552 -8.330603 1.058979\n",
            "553 -8.56727 0.971107\n",
            "554 -7.691341 1.11251\n",
            "555 -7.541522 1.025435\n",
            "556 -8.738693 1.124424\n",
            "557 -7.884165 1.08087\n",
            "558 -8.067413 1.070721\n",
            "559 -8.097648 1.147032\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "caSmwvfCI4KK",
        "colab_type": "text"
      },
      "source": [
        "## GAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "r1Mv0S8hcUL5",
        "colab": {}
      },
      "source": [
        "# Generator.eval()\n",
        "# generated_image = Generator(torch.randn([1,100]).to(device)).cpu().detach().numpy()[0].transpose(1,2,0)\n",
        "# generated_image02 = (((generated_image - generated_image.min())/((generated_image - generated_image.min()).max()))*255).astype(int)\n",
        "# img = Image.fromarray(np.uint8((generated_image02)))\n",
        "# Generator.train()\n",
        "# try:\n",
        "#   img.save('./drive/My Drive/Colab Notebooks/mlstudy/gan/gdl_code/fig/image.png')\n",
        "# except:\n",
        "#   pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdutjRq6aZsN",
        "colab_type": "code",
        "outputId": "ddf8236d-3bb0-43a1-d63d-d40b84d2dbaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "Generator.eval()\n",
        "plt.imshow(Generator(torch.randn([1,100]).to(device)).cpu().detach().numpy()[0].transpose(1,2,0))\n",
        "Generator.train()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f95445d1710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 665
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-5gSSF3I6yz",
        "colab_type": "text"
      },
      "source": [
        "## WGAN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmqTocPZI6g6",
        "colab_type": "code",
        "outputId": "8a67c197-8ed6-4b91-9531-3cc318a28f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "Generator.eval()\n",
        "plt.imshow(Generator(torch.randn([1,100]).to(device)).cpu().detach().numpy()[0].transpose(1,2,0))\n",
        "Generator.train()\n",
        "print(1)"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngl2ISFCwCxEJCnYhIuH/AmReoxgCYv1YAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nY4M8LLpI9Iz",
        "colab_type": "text"
      },
      "source": [
        "## WGAN-GP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZihgzdn4MFq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.imshow(Generator(torch.randn([1,100]).to(device)).cpu().detach().numpy()[0].transpose(1,2,0))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}