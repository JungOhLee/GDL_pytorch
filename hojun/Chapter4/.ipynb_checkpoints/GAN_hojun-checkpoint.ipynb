{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd.variable import Variable\n",
    "from Discriminator_hojun import Discriminator\n",
    "from Generator_hojun import Generator, make_layers, get_activation\n",
    "from utils.loaders import load_safari\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plot\n",
    "import json\n",
    "import pickle as pkl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 200\n",
    "batch_size = 128\n",
    "learning_rate = 0.0004\n",
    "device = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "DATA_NAME='camel'\n",
    "(x_train, y_train) = load_safari(DATA_NAME)\n",
    "_x_train = np.transpose(x_train, (0,3,1,2))\n",
    "_y_train=np.array(y_train)\n",
    "x_train = torch.from_numpy(_x_train).to(device)\n",
    "y_train= torch.from_numpy(_y_train).to(device)\n",
    "input_data = [[x_item, y_item] for x_item, y_item in zip(x_train, y_train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(input_dim=(60,1,28,28), discriminator_conv_channels = [64,64,128,128],\n",
    "    discriminator_conv_kernel_size = [5,5,5,5], discriminator_conv_strides = [2,2,2,1],\n",
    "    discriminator_batch_norm_momentum = None, discriminator_activation = 'relu',\n",
    "    discriminator_dropout_rate = 0.4).to(device)\n",
    "generator=Generator(input_dim=100, generator_initial_dense_layer_size = (64, 7, 7)\n",
    "        , generator_upsample = [2,2, 1, 1]\n",
    "        , generator_conv_channels = [128,64, 64,1]\n",
    "        , generator_conv_kernel_size = [5,5,5,5]\n",
    "        , generator_conv_strides = [1,1, 1, 1]\n",
    "        , generator_batch_norm_momentum = 0.9\n",
    "        , generator_activation = 'relu').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(model):\n",
    "    for p in model.parameters():\n",
    "        if(p.dim() > 1):\n",
    "            nn.init.xavier_normal_(p)\n",
    "        else:\n",
    "            nn.init.uniform_(p, 0.1, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_params(generator)\n",
    "init_params(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "camel_loader=DataLoader(input_data, batch_size=batch_size, shuffle=True)\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "discriminator_optimizer = torch.optim.Adam(discriminator.parameters(), lr=learning_rate)\n",
    "generator_optimizer = torch.optim.Adam(generator.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: Discriminator Loss=1.0829, Generator Loss=0.2703\n",
      "1: Discriminator Loss=0.3433, Generator Loss=0.3403\n",
      "2: Discriminator Loss=0.8593, Generator Loss=1.2696\n",
      "3: Discriminator Loss=0.1432, Generator Loss=1.2632\n",
      "4: Discriminator Loss=0.1375, Generator Loss=1.7921\n",
      "5: Discriminator Loss=0.1485, Generator Loss=2.3289\n",
      "6: Discriminator Loss=0.4046, Generator Loss=1.8123\n",
      "7: Discriminator Loss=0.0288, Generator Loss=1.5002\n",
      "8: Discriminator Loss=0.0028, Generator Loss=3.0021\n",
      "9: Discriminator Loss=0.0137, Generator Loss=2.1478\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "for epoch in range(num_epochs):\n",
    "    for _, (x_batch, y_batch) in enumerate(camel_loader):\n",
    "        x_batch = x_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        if len(x_batch)<batch_size:\n",
    "            valid_discriminator = torch.ones((len(x_batch),1))\n",
    "            fake_discriminator = torch.zeros((len(x_batch),1))\n",
    "        else:\n",
    "            valid_discriminator = torch.ones((batch_size,1))\n",
    "            fake_discriminator = torch.zeros((batch_size,1))\n",
    "        \n",
    "        valid_discriminator=Variable(valid_discriminator).to(device)\n",
    "        fake_discriminator=Variable(fake_discriminator).to(device)\n",
    "        noise =Variable(torch.normal(0, 1.0, (batch_size, 100))).to(device)\n",
    "        gen_x_batch = generator(noise)\n",
    "        total_x_batch=torch.cat((gen_x_batch, x_batch), 0)\n",
    "        predicted_labels=discriminator(total_x_batch)\n",
    "        labels=torch.cat((fake_discriminator, valid_discriminator), 0)\n",
    "        predicted_labels=predicted_labels.squeeze(1)\n",
    "        labels=labels.squeeze(1)\n",
    "        \n",
    "        discriminator_loss = criterion(predicted_labels, labels).to(device)\n",
    "        # Backward and optimize\n",
    "        discriminator_optimizer.zero_grad()\n",
    "        discriminator_loss.backward()\n",
    "        discriminator_optimizer.step()\n",
    "        \n",
    "        \n",
    "        valid_generator = Variable(torch.ones([batch_size,1])).to(device).squeeze(1)\n",
    "        noise_generator = Variable(torch.Tensor(np.random.normal(0, 1, (batch_size, 100)))).to(device)\n",
    "        output_generator = generator(noise_generator)\n",
    "        output_generator = discriminator(output_generator).squeeze(1)\n",
    "        generator_loss=criterion(output_generator, valid_generator)\n",
    "        generator_optimizer.zero_grad()\n",
    "        generator_loss.backward()\n",
    "        generator_optimizer.step()\n",
    "        \n",
    "    print(\"%d: Discriminator Loss=%.4f, Generator Loss=%.4f\" % (\n",
    "        epoch, 10000*discriminator_loss.item(), generator_loss.item()))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 100])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample=torch.normal(0, 1, [2, 100])\n",
    "test_sample=test_sample.to(device)\n",
    "test_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result=generator(test_sample).to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f55a0cf7390>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(test_result.detach().numpy()[0].transpose([1,2,0]).reshape([28,28]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_x=torch.Tensor(np.random.normal(0, 1, (batch_size, 100)))\n",
    "# class generator_layer1(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(generator_layer1, self).__init__()\n",
    "#         self.conv=nn.Sequential(\n",
    "#             nn.Linear(100, 3136)\n",
    "#         )\n",
    "#     def forward(self, x):\n",
    "#         x=self.conv(x)\n",
    "#         return(x)\n",
    "# generator(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class generator_layer2(nn.Module):\n",
    "#     def __init__(self, in_channel=64, out_channel=128, kernel_size=5, padding=2, batchnorm_momentum=0.1):\n",
    "#         super(generator_layer2, self).__init__()\n",
    "#        self.conv=nn.Sequential(\n",
    "#        nn.Upsample(scale_factor=2),\n",
    "#        nn.Conv2d(in_channel, out_channel, kernel_size=kernel_size, padding=padding),\n",
    "#        nn.BatchNorm2d(out_channel, momentum=batchnorm_momentum),\n",
    "#        get_activation()\n",
    "#        )\n",
    "#         self.conv1=nn.Conv2d(in_channels=64, out_channels=128, kernel_size=5, padding=2)\n",
    "        \n",
    "#     make_layers(in_channel=64, out_channel=128, kernel_size=5, padding=2, batchnorm_momentum=0.1)\n",
    "#     def forward(self, x):\n",
    "#         x=x.view(-1, 64, 7, 7)\n",
    "#         print(x.shape)\n",
    "#         x=self.conv1(x)\n",
    "#         return(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "gan"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
